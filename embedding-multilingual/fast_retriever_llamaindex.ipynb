{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a28003aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_embedding import load_qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2eb11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"QA/gpt-35-turbo_dataset.json\"\n",
    "baseline_model_id = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "finetuned_model_id = \"finetuned-sentence-transformers/finetuned-paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "top_k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f25287cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-22 20:49:38.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.utils_embedding\u001b[0m:\u001b[36mload_qa_dataset\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading dataset from QA/gpt-35-turbo_dataset.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = load_qa_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01548d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: finetuned-sentence-transformers/finetuned-paraphrase-multilingual-MiniLM-L12-v2\n",
      "Load pretrained SentenceTransformer: finetuned-sentence-transformers/finetuned-paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model_paraphrase_l12 = HuggingFaceEmbedding(model_name=finetuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f405ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some nodes are missing content, skipping them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 258/258 [00:01<00:00, 215.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "corpus = dataset.corpus\n",
    "queries = dataset.queries\n",
    "relevant_docs = dataset.relevant_docs\n",
    "\n",
    "nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
    "index = VectorStoreIndex(nodes, embed_model=embed_model_paraphrase_l12 , show_progress=True)\n",
    "retriever = index.as_retriever(similarity_top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6a98005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "metrics = [\"hit_rate\", \"mrr\", \"precision\", \"recall\", \"ap\", \"ndcg\"]\n",
    "\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "917f2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "eval_results = await retriever_evaluator.aevaluate_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "541f5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_results(name, eval_results):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "    metric_dicts = []\n",
    "    for eval_result in eval_results:\n",
    "        metric_dict = eval_result.metric_vals_dict\n",
    "        metric_dicts.append(metric_dict)\n",
    "    full_df = pd.DataFrame(metric_dicts)\n",
    "    columns = {\n",
    "        \"retrievers\": [name],\n",
    "        **{k: [full_df[k].mean()] for k in metrics},\n",
    "    }\n",
    "    metric_df = pd.DataFrame(columns)\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1f8645c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top-1 eval</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.685256</td>\n",
       "      <td>0.258974</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.685256</td>\n",
       "      <td>0.708834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr  precision    recall        ap      ndcg\n",
       "0  top-1 eval  0.776923  0.685256   0.258974  0.776923  0.685256  0.708834"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_results(\"top-1 eval\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6d4a29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top-5 eval</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.685256</td>\n",
       "      <td>0.258974</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.685256</td>\n",
       "      <td>0.708834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr  precision    recall        ap      ndcg\n",
       "0  top-5 eval  0.776923  0.685256   0.258974  0.776923  0.685256  0.708834"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "display_results(\"top-5 eval\", eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
