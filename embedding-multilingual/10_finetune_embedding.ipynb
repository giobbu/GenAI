{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09f34a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 10 threads.\n",
      "NumExpr defaulting to 10 threads.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "from utils.utils_embedding import load_qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3496aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to = \"codice\"\n",
    "dataset_name = \"QA/\" + path_to + \"/gpt-35-turbo_temperature_1_dataset.json\"\n",
    "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model_output_path_name = f\"finetuned-sentence-transformers/\" + path_to + f\"/finetuned-paraphrase-multilingual-MiniLM-L12-v2_{dataset_name.split('/')[-1].split('.')[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63b6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_finetuning(dataset_name, model_name, model_output_path_name):\n",
    "    \"\"\" \n",
    "    Finetune the Sentence Transformers model on the specified dataset.\n",
    "    \"\"\"\n",
    "    qa_dataset = load_qa_dataset(dataset_name)\n",
    "    finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "                                                        qa_dataset,\n",
    "                                                        model_id=model_name,\n",
    "                                                        model_output_path=model_output_path_name,\n",
    "                                                        val_dataset=qa_dataset,\n",
    "                                                        )\n",
    "    finetune_engine.finetune()\n",
    "    finetuned_embed_model = finetune_engine.get_finetuned_model()\n",
    "    return finetuned_embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cd1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 17:27:21.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.utils_embedding\u001b[0m:\u001b[36mload_qa_dataset\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mLoading dataset from QA/codice/gpt-35-turbo_temperature_1_dataset.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/agent/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='142' max='142' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [142/142 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cosine Accuracy@1</th>\n",
       "      <th>Cosine Accuracy@3</th>\n",
       "      <th>Cosine Accuracy@5</th>\n",
       "      <th>Cosine Accuracy@10</th>\n",
       "      <th>Cosine Precision@1</th>\n",
       "      <th>Cosine Precision@3</th>\n",
       "      <th>Cosine Precision@5</th>\n",
       "      <th>Cosine Precision@10</th>\n",
       "      <th>Cosine Recall@1</th>\n",
       "      <th>Cosine Recall@3</th>\n",
       "      <th>Cosine Recall@5</th>\n",
       "      <th>Cosine Recall@10</th>\n",
       "      <th>Cosine Ndcg@10</th>\n",
       "      <th>Cosine Mrr@10</th>\n",
       "      <th>Cosine Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.440967</td>\n",
       "      <td>0.560455</td>\n",
       "      <td>0.611664</td>\n",
       "      <td>0.669986</td>\n",
       "      <td>0.440967</td>\n",
       "      <td>0.186818</td>\n",
       "      <td>0.122333</td>\n",
       "      <td>0.066999</td>\n",
       "      <td>0.440967</td>\n",
       "      <td>0.560455</td>\n",
       "      <td>0.611664</td>\n",
       "      <td>0.669986</td>\n",
       "      <td>0.550262</td>\n",
       "      <td>0.512562</td>\n",
       "      <td>0.519534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.455192</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.685633</td>\n",
       "      <td>0.455192</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.124324</td>\n",
       "      <td>0.068563</td>\n",
       "      <td>0.455192</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.685633</td>\n",
       "      <td>0.563154</td>\n",
       "      <td>0.524846</td>\n",
       "      <td>0.532261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466572</td>\n",
       "      <td>0.588905</td>\n",
       "      <td>0.640114</td>\n",
       "      <td>0.711238</td>\n",
       "      <td>0.466572</td>\n",
       "      <td>0.196302</td>\n",
       "      <td>0.128023</td>\n",
       "      <td>0.071124</td>\n",
       "      <td>0.466572</td>\n",
       "      <td>0.588905</td>\n",
       "      <td>0.640114</td>\n",
       "      <td>0.711238</td>\n",
       "      <td>0.581439</td>\n",
       "      <td>0.540810</td>\n",
       "      <td>0.548249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.463727</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.652916</td>\n",
       "      <td>0.722617</td>\n",
       "      <td>0.463727</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>0.130583</td>\n",
       "      <td>0.072262</td>\n",
       "      <td>0.463727</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.652916</td>\n",
       "      <td>0.722617</td>\n",
       "      <td>0.586101</td>\n",
       "      <td>0.543198</td>\n",
       "      <td>0.550750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the  dataset in epoch 0.704225352112676 after 50 steps:\n",
      "Information Retrieval Evaluation of the model on the  dataset in epoch 0.704225352112676 after 50 steps:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 703\n",
      "Queries: 703\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 703\n",
      "\n",
      "Corpus: 703\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 44.10%\n",
      "Accuracy@1: 44.10%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 56.05%\n",
      "Accuracy@3: 56.05%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 61.17%\n",
      "Accuracy@5: 61.17%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 67.00%\n",
      "Accuracy@10: 67.00%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 44.10%\n",
      "Precision@1: 44.10%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 18.68%\n",
      "Precision@3: 18.68%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 12.23%\n",
      "Precision@5: 12.23%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 6.70%\n",
      "Precision@10: 6.70%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 44.10%\n",
      "Recall@1: 44.10%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 56.05%\n",
      "Recall@3: 56.05%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 61.17%\n",
      "Recall@5: 61.17%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 67.00%\n",
      "Recall@10: 67.00%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.5126\n",
      "MRR@10: 0.5126\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.5503\n",
      "NDCG@10: 0.5503\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.5195\n",
      "MAP@100: 0.5195\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n",
      "Save model to finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the  dataset in epoch 1.0 after 71 steps:\n",
      "Information Retrieval Evaluation of the model on the  dataset in epoch 1.0 after 71 steps:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 703\n",
      "Queries: 703\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 703\n",
      "\n",
      "Corpus: 703\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 45.52%\n",
      "Accuracy@1: 45.52%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 56.76%\n",
      "Accuracy@3: 56.76%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 62.16%\n",
      "Accuracy@5: 62.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 68.56%\n",
      "Accuracy@10: 68.56%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 45.52%\n",
      "Precision@1: 45.52%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 18.92%\n",
      "Precision@3: 18.92%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 12.43%\n",
      "Precision@5: 12.43%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 6.86%\n",
      "Precision@10: 6.86%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 45.52%\n",
      "Recall@1: 45.52%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 56.76%\n",
      "Recall@3: 56.76%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 62.16%\n",
      "Recall@5: 62.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 68.56%\n",
      "Recall@10: 68.56%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.5248\n",
      "MRR@10: 0.5248\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.5632\n",
      "NDCG@10: 0.5632\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.5323\n",
      "MAP@100: 0.5323\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n",
      "Save model to finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the  dataset in epoch 1.408450704225352 after 100 steps:\n",
      "Information Retrieval Evaluation of the model on the  dataset in epoch 1.408450704225352 after 100 steps:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 703\n",
      "Queries: 703\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 703\n",
      "\n",
      "Corpus: 703\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 46.66%\n",
      "Accuracy@1: 46.66%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 58.89%\n",
      "Accuracy@3: 58.89%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 64.01%\n",
      "Accuracy@5: 64.01%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 71.12%\n",
      "Accuracy@10: 71.12%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 46.66%\n",
      "Precision@1: 46.66%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 19.63%\n",
      "Precision@3: 19.63%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 12.80%\n",
      "Precision@5: 12.80%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 7.11%\n",
      "Precision@10: 7.11%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 46.66%\n",
      "Recall@1: 46.66%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 58.89%\n",
      "Recall@3: 58.89%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 64.01%\n",
      "Recall@5: 64.01%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 71.12%\n",
      "Recall@10: 71.12%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.5408\n",
      "MRR@10: 0.5408\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.5814\n",
      "NDCG@10: 0.5814\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.5482\n",
      "MAP@100: 0.5482\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n",
      "Save model to finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the  dataset in epoch 2.0 after 142 steps:\n",
      "Information Retrieval Evaluation of the model on the  dataset in epoch 2.0 after 142 steps:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 703\n",
      "Queries: 703\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 703\n",
      "\n",
      "Corpus: 703\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 46.37%\n",
      "Accuracy@1: 46.37%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 59.46%\n",
      "Accuracy@3: 59.46%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 65.29%\n",
      "Accuracy@5: 65.29%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 72.26%\n",
      "Accuracy@10: 72.26%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 46.37%\n",
      "Precision@1: 46.37%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 19.82%\n",
      "Precision@3: 19.82%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 13.06%\n",
      "Precision@5: 13.06%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 7.23%\n",
      "Precision@10: 7.23%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 46.37%\n",
      "Recall@1: 46.37%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 59.46%\n",
      "Recall@3: 59.46%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 65.29%\n",
      "Recall@5: 65.29%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 72.26%\n",
      "Recall@10: 72.26%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.5432\n",
      "MRR@10: 0.5432\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.5861\n",
      "NDCG@10: 0.5861\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.5507\n",
      "MAP@100: 0.5507\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n",
      "Save model to finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n",
      "Load pretrained SentenceTransformer: finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbedding(model_name='finetuned-sentence-transformers/codice/finetuned-paraphrase-multilingual-MiniLM-L12-v2_gpt-35-turbo_temperature_1_dataset', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x10915be90>, num_workers=None, embeddings_cache=None, max_length=128, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None, show_progress_bar=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_embed_model = run_finetuning(dataset_name, model_name, model_output_path_name)\n",
    "finetuned_embed_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
