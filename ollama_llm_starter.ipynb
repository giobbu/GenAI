{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a265689a",
   "metadata": {},
   "source": [
    "# Ollama Finetuning\n",
    "* transformers fix: pip install transformers==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55002a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.bridge.pydantic import BaseModel\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adceffd",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "507132d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class configLLM:\n",
    "    model_name = \"llama3.1:latest\"\n",
    "    request_timeout = 240.0\n",
    "    json_mode= True\n",
    "    context_window = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73e6de",
   "metadata": {},
   "source": [
    "## set LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4889082",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = configLLM()\n",
    "\n",
    "llm = Ollama(\n",
    "    model=params.model_name,\n",
    "    request_timeout=params.request_timeout,\n",
    "    context_window=params.context_window,\n",
    "    json_mode=params.json_mode\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a642dd",
   "metadata": {},
   "source": [
    "### structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1c1af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredOutput(BaseModel):\n",
    "    \"\"\"\n",
    "    Example of structured output\n",
    "    \"\"\"\n",
    "    answer: str\n",
    "    confidence: float\n",
    "    explanation: str\n",
    "    llm_name: str = llm.model\n",
    "\n",
    "structured_llm = llm.as_structured_llm(StructuredOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e64c18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = structured_llm.complete(\"Who is Paul Graham?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c27c78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "str_resp = resp.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0992377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-08 17:45:28.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mResponse: {'text': '{\"answer\":\"Paul Graham is a well-known British-American programmer, writer, and venture capitalist. He\\'s best known for co-founding the online startup incubator Y Combinator in 2005, which has invested in many successful companies like Dropbox, Airbnb, and Reddit.\",\"confidence\":1.0,\"explanation\":\"Paul Graham was born in London in 1964 but moved to the US in his youth. He studied at Cambridge University, then Harvard, where he co-founded Viaweb (later renamed as Yahoo! Store) with Robert Tappan Morris.\",\"llm_name\":\"llama3.1:latest\"}', 'additional_kwargs': {}, 'raw': {'answer': \"Paul Graham is a well-known British-American programmer, writer, and venture capitalist. He's best known for co-founding the online startup incubator Y Combinator in 2005, which has invested in many successful companies like Dropbox, Airbnb, and Reddit.\", 'confidence': 1.0, 'explanation': 'Paul Graham was born in London in 1964 but moved to the US in his youth. He studied at Cambridge University, then Harvard, where he co-founded Viaweb (later renamed as Yahoo! Store) with Robert Tappan Morris.', 'llm_name': 'llama3.1:latest'}, 'logprobs': None, 'delta': None}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# convert to dict\n",
    "dict_resp = json.loads(str_resp)\n",
    "logger.info(f\"Response: {dict_resp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57754ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dict_resp[\"text\"]\n",
    "# fom string to dict\n",
    "text_dict = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d659196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Document\n",
    "doc = Document()\n",
    "# add a title\n",
    "doc.add_heading('LLM structured Response', level=1)\n",
    "# add a paragraph with the response\n",
    "doc.add_heading('Answer', level=2)\n",
    "doc.add_paragraph(f\"{text_dict['answer']}\")\n",
    "doc.add_heading('Confidence', level=2)\n",
    "doc.add_paragraph(f\"{text_dict['confidence']}\")\n",
    "doc.add_heading('Explanation', level=2)\n",
    "doc.add_paragraph(f\"{text_dict['explanation']}\")\n",
    "doc.add_heading('LLM Name', level=2)\n",
    "doc.add_paragraph(f\"{text_dict['llm_name']}\")\n",
    "# save the document overwrite\n",
    "doc.save('llm_response.docx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
